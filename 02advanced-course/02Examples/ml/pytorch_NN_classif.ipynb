{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a527751e-a79a-49c7-a8ac-08f0537c1acc",
   "metadata": {},
   "source": [
    "# Pytorch: simple NN for binary classification\n",
    "\n",
    "\n",
    "For the PIMA Indians data on diabetes (already encountered in the Basic Course), we will set up a feedforward net to predict the diabetes status.\n",
    "\n",
    "We follow the usual workflow:\n",
    "\n",
    "1. Load the data.\n",
    "2. Define the pytorch model.\n",
    "3. Define the loss function and optimizer.\n",
    "4. Run the training loop.\n",
    "5. Evaluate the model.\n",
    "6. Make predictions with the learned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4d8898-9f86-42c2-ac7e-b2da3f8c3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1180a6-e682-47df-9a66-0943bd155ebc",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "Input Variables ( $X$ ):\n",
    "\n",
    "- Number of times pregnant\n",
    "- Plasma glucose concentration at 2 hours in an oral glucose tolerance test\n",
    "- Diastolic blood pressure (mm Hg)\n",
    "- Triceps skin fold thickness (mm)\n",
    "- 2-hour serum insulin (Î¼IU/ml)\n",
    "- Body mass index BMI (weight in kg/(height in m)2)\n",
    "- Diabetes pedigree function\n",
    "- Age (years)\n",
    "\n",
    "Output Variable  ( $y$ ):\n",
    "\n",
    "- Class label (0 or 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a95df88-29c8-45c7-9a97-be9ab8b2ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868862a-b91c-4c66-943f-05ee2666dddb",
   "metadata": {},
   "source": [
    "Convert numpy arrays to pytorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f6f72f-e27d-4fb7-a81b-2c749bae184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22544116-9ba4-4315-b66e-c83795d7c724",
   "metadata": {},
   "source": [
    "## 2. Define the model\n",
    "\n",
    "We will use\n",
    "\n",
    "- fully connected layers or dense layers using the `Linear` class in PyTorch.\n",
    "- ReLU activation functions\n",
    "- Sigmoid output for the final classification in the output layer (0/1)\n",
    "\n",
    "Use a \"pyramidal\" architecture... (see previous Examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34643da8-5aea-4277-b6c1-455a7fc7268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid() )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7ca5-1870-4bf0-b650-b2f85b2cadd1",
   "metadata": {},
   "source": [
    "An alternative is to use a class inherited from `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902bf599-25ef-44df-887e-6217f74d7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(8, 12)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(12, 8)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = PimaClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13ee27-8ce3-4ab5-b798-23fe512f07a6",
   "metadata": {},
   "source": [
    "## 3. Set up loss and optimizer\n",
    "\n",
    "Since we have a binary classification problem, we must use the binary classification error loss function, `BCELoss`.\n",
    "\n",
    "For the optimizer, we use standard `Adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3be30d-f575-4844-8c46-fe5477279c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfdb50-4fd3-4a43-85b3-531dbf5cdbcf",
   "metadata": {},
   "source": [
    "## 4. Train the model.\n",
    "\n",
    "- Loop over the epochs, \n",
    "  - loop over batches\n",
    "    - compute loss\n",
    "    - compute gradient (backward)\n",
    "    - step the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1719725d-84c0-4854-9533-3d67c0e7f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At end of epoch 0, loss = 0.6514326333999634\n",
      "At end of epoch 1, loss = 0.4459029734134674\n",
      "At end of epoch 2, loss = 0.4550330638885498\n",
      "At end of epoch 3, loss = 0.4522790312767029\n",
      "At end of epoch 4, loss = 0.4477901756763458\n",
      "At end of epoch 5, loss = 0.44486045837402344\n",
      "At end of epoch 6, loss = 0.4469968378543854\n",
      "At end of epoch 7, loss = 0.4473118484020233\n",
      "At end of epoch 8, loss = 0.44760721921920776\n",
      "At end of epoch 9, loss = 0.44560447335243225\n",
      "At end of epoch 10, loss = 0.4458388388156891\n",
      "At end of epoch 11, loss = 0.4470572769641876\n",
      "At end of epoch 12, loss = 0.4462440311908722\n",
      "At end of epoch 13, loss = 0.44738638401031494\n",
      "At end of epoch 14, loss = 0.448482871055603\n",
      "At end of epoch 15, loss = 0.4486386179924011\n",
      "At end of epoch 16, loss = 0.4485207200050354\n",
      "At end of epoch 17, loss = 0.4487292170524597\n",
      "At end of epoch 18, loss = 0.44715577363967896\n",
      "At end of epoch 19, loss = 0.4507614076137543\n",
      "At end of epoch 20, loss = 0.45241180062294006\n",
      "At end of epoch 21, loss = 0.4519551694393158\n",
      "At end of epoch 22, loss = 0.45340585708618164\n",
      "At end of epoch 23, loss = 0.4532201886177063\n",
      "At end of epoch 24, loss = 0.4546703100204468\n",
      "At end of epoch 25, loss = 0.4543384313583374\n",
      "At end of epoch 26, loss = 0.45460227131843567\n",
      "At end of epoch 27, loss = 0.45427581667900085\n",
      "At end of epoch 28, loss = 0.45509073138237\n",
      "At end of epoch 29, loss = 0.4552815556526184\n",
      "At end of epoch 30, loss = 0.45616254210472107\n",
      "At end of epoch 31, loss = 0.4565679132938385\n",
      "At end of epoch 32, loss = 0.4559328854084015\n",
      "At end of epoch 33, loss = 0.4559021592140198\n",
      "At end of epoch 34, loss = 0.4552902579307556\n",
      "At end of epoch 35, loss = 0.45252037048339844\n",
      "At end of epoch 36, loss = 0.4505394697189331\n",
      "At end of epoch 37, loss = 0.44697901606559753\n",
      "At end of epoch 38, loss = 0.4421866238117218\n",
      "At end of epoch 39, loss = 0.43972349166870117\n",
      "At end of epoch 40, loss = 0.4366328716278076\n",
      "At end of epoch 41, loss = 0.4346984028816223\n",
      "At end of epoch 42, loss = 0.43227678537368774\n",
      "At end of epoch 43, loss = 0.43260636925697327\n",
      "At end of epoch 44, loss = 0.4313752055168152\n",
      "At end of epoch 45, loss = 0.4310115575790405\n",
      "At end of epoch 46, loss = 0.4309276342391968\n",
      "At end of epoch 47, loss = 0.4298495650291443\n",
      "At end of epoch 48, loss = 0.42906877398490906\n",
      "At end of epoch 49, loss = 0.4287033677101135\n",
      "At end of epoch 50, loss = 0.42760005593299866\n",
      "At end of epoch 51, loss = 0.42689645290374756\n",
      "At end of epoch 52, loss = 0.4261499047279358\n",
      "At end of epoch 53, loss = 0.42485707998275757\n",
      "At end of epoch 54, loss = 0.4237571060657501\n",
      "At end of epoch 55, loss = 0.42292535305023193\n",
      "At end of epoch 56, loss = 0.4225464463233948\n",
      "At end of epoch 57, loss = 0.4221575856208801\n",
      "At end of epoch 58, loss = 0.4213806986808777\n",
      "At end of epoch 59, loss = 0.4214887320995331\n",
      "At end of epoch 60, loss = 0.4206361472606659\n",
      "At end of epoch 61, loss = 0.42072466015815735\n",
      "At end of epoch 62, loss = 0.42008012533187866\n",
      "At end of epoch 63, loss = 0.41975465416908264\n",
      "At end of epoch 64, loss = 0.4193488359451294\n",
      "At end of epoch 65, loss = 0.4189695417881012\n",
      "At end of epoch 66, loss = 0.4194849133491516\n",
      "At end of epoch 67, loss = 0.419280081987381\n",
      "At end of epoch 68, loss = 0.41929611563682556\n",
      "At end of epoch 69, loss = 0.4180874824523926\n",
      "At end of epoch 70, loss = 0.4179556965827942\n",
      "At end of epoch 71, loss = 0.4178284704685211\n",
      "At end of epoch 72, loss = 0.4190225303173065\n",
      "At end of epoch 73, loss = 0.4191664457321167\n",
      "At end of epoch 74, loss = 0.4188390076160431\n",
      "At end of epoch 75, loss = 0.4191761314868927\n",
      "At end of epoch 76, loss = 0.4176833927631378\n",
      "At end of epoch 77, loss = 0.41882672905921936\n",
      "At end of epoch 78, loss = 0.41919586062431335\n",
      "At end of epoch 79, loss = 0.41920986771583557\n",
      "At end of epoch 80, loss = 0.4184538722038269\n",
      "At end of epoch 81, loss = 0.4185410141944885\n",
      "At end of epoch 82, loss = 0.4179275631904602\n",
      "At end of epoch 83, loss = 0.4187832772731781\n",
      "At end of epoch 84, loss = 0.41979092359542847\n",
      "At end of epoch 85, loss = 0.4191528856754303\n",
      "At end of epoch 86, loss = 0.41897183656692505\n",
      "At end of epoch 87, loss = 0.4188595414161682\n",
      "At end of epoch 88, loss = 0.4189137816429138\n",
      "At end of epoch 89, loss = 0.4185986816883087\n",
      "At end of epoch 90, loss = 0.4165605902671814\n",
      "At end of epoch 91, loss = 0.41700321435928345\n",
      "At end of epoch 92, loss = 0.41613277792930603\n",
      "At end of epoch 93, loss = 0.413994163274765\n",
      "At end of epoch 94, loss = 0.4150134027004242\n",
      "At end of epoch 95, loss = 0.4148235023021698\n",
      "At end of epoch 96, loss = 0.41368621587753296\n",
      "At end of epoch 97, loss = 0.41401827335357666\n",
      "At end of epoch 98, loss = 0.4144798219203949\n",
      "At end of epoch 99, loss = 0.41475769877433777\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        y_pred  = model(X_batch)\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'At end of epoch {epoch}, loss = {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e361a2-9c41-4908-8b0a-1ab7164269d3",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model precision\n",
    "\n",
    "Just evaluate on all the training data...not very satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d60bfdd-a791-421e-803d-d60d2f0251d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7421875\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32075fdd-1a37-4702-a082-2c8ecbb27c7f",
   "metadata": {},
   "source": [
    "## 6. Make predictions with model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8868eee3-77a9-4ab5-838b-47912953a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.599998474121094, 0.6269999742507935, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.600000381469727, 0.35100001096725464, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.299999237060547, 0.671999990940094, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.100000381469727, 0.16699999570846558, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.099998474121094, 2.2880001068115234, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# make class predictions with the model\n",
    "predictions = (model(X) > 0.5).int()\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7982c",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "1. In spite of relatively large learning error, and no real cross-validation, the classifier attained 100% accuracy on the \"test\" set.\n",
    "2. The model should be redone with\n",
    "   - complete EDA (see previous Example)\n",
    "   - proper trian/test split\n",
    "   - tuning of architecture\n",
    "   - tuning of optimizer\n",
    "   - rigorous reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de869a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
